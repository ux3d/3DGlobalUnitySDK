#include "Packages/com.unity.render-pipelines.high-definition/Runtime/RenderPipeline/RenderPass/CustomPass/CustomPassCommon.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/ShaderLibrary/ShaderVariables.hlsl"
#include "G3DHLSLCommonFunctions.hlsl"

#pragma kernel main

Texture2D _depthMosaic;
SamplerState sampler_depthMosaic;
Texture2D _colorMosaic;
SamplerState sampler_colorMosaic;

// Create a RenderTexture with enableRandomWrite flag and set it
// with cs.SetTexture
RWTexture2D<float4> Result;

float4x4 viewMatrices[16];
float4x4 invProjMatrices[16];



int2 gridSize;
int radius;
float sigma;

int2 imageSize;

Texture2D _depthMap0;
Texture2D _depthMap1;
Texture2D _depthMap2;
Texture2D _depthMap3;
Texture2D _depthMap4;
Texture2D _depthMap5;
Texture2D _depthMap6;
Texture2D _depthMap7;
Texture2D _depthMap8;
Texture2D _depthMap9;
Texture2D _depthMap10;
Texture2D _depthMap11;
Texture2D _depthMap12;
Texture2D _depthMap13;
Texture2D _depthMap14;
Texture2D _depthMap15;

SamplerState sampler_linear_repeat;

// Set the texture array as a shader input
float getCameraLogDepth(float2 uv, int cameraIndex) {
    switch(cameraIndex) {
        case 0:
            return _depthMap0.SampleLevel(sampler_linear_repeat, uv, 0).r;
        case 1:
            return _depthMap1.SampleLevel(sampler_linear_repeat, uv, 0).r;
        case 2:
            return _depthMap2.SampleLevel(sampler_linear_repeat, uv, 0).r;
        case 3:
            return _depthMap3.SampleLevel(sampler_linear_repeat, uv, 0).r;
        case 4:
            return _depthMap4.SampleLevel(sampler_linear_repeat, uv, 0).r;
        case 5:
            return _depthMap5.SampleLevel(sampler_linear_repeat, uv, 0).r;
        case 6:
            return _depthMap6.SampleLevel(sampler_linear_repeat, uv, 0).r;
        case 7:
            return _depthMap7.SampleLevel(sampler_linear_repeat, uv, 0).r;
        case 8:
            return _depthMap8.SampleLevel(sampler_linear_repeat, uv, 0).r;
        case 9:
            return _depthMap9.SampleLevel(sampler_linear_repeat, uv, 0).r;  
        case 10:
            return _depthMap10.SampleLevel(sampler_linear_repeat, uv, 0).r;  
        case 11:
            return _depthMap11.SampleLevel(sampler_linear_repeat, uv, 0).r;  
        case 12:
            return _depthMap12.SampleLevel(sampler_linear_repeat, uv, 0).r;  
        case 13:
            return _depthMap13.SampleLevel(sampler_linear_repeat, uv, 0).r;  
        case 14:
            return _depthMap14.SampleLevel(sampler_linear_repeat, uv, 0).r;  
        case 15:
            return _depthMap15.SampleLevel(sampler_linear_repeat, uv, 0).r;  
        default:
            return _depthMap0.SampleLevel(sampler_linear_repeat, uv, 0).r; // use left camera depth map as default
    }
}

float4x4 getInvProjMatrix(int viewIndex) {
    return invProjMatrices[viewIndex];
}

float4x4 getViewMatrix(int viewIndex) {
    return viewMatrices[viewIndex];
}

// here UV is treated as a full screen UV coordinate
float2 calculateProjectedFragmentPosition(float2 uv, int viewIndex, float4x4 viewProjectionMatrix) {
    float logDepth = getCameraLogDepth(uv, viewIndex);
    // Sample the depth from the Camera depth texture.
    float deviceDepth = logDepth;

    // Reconstruct the world space positions.
    float3 worldPos = ComputeWorldSpacePosition(uv, deviceDepth, getInvProjMatrix(viewIndex));

    float3 NDC = ComputeNormalizedDeviceCoordinatesWithZ(worldPos, viewProjectionMatrix); // convert from clip space to NDC coordinates
    
    return float2(NDC.xy); // return the difference between the shifted and original x coordinate
}

float Linear01DepthViewBased(float2 uv, int viewIndex) {
    float logDepth = getCameraLogDepth(uv, viewIndex);
    // Sample the depth from the Camera depth texture.
    float deviceDepth = logDepth;
    float3 worldPos = ComputeWorldSpacePosition(uv, deviceDepth, getInvProjMatrix(viewIndex));
    float eyeDepth = LinearEyeDepth(worldPos, getViewMatrix(viewIndex));
    return eyeDepth / _ProjectionParams.z; // convert to linear depth in range [0, 1]
}

float4 getColorMosaic(float2 uv, int viewIndex) {
    float2 fragmentUV = calculateUVForMosaic(viewIndex, uv, gridSize.y, gridSize.x);
    return _colorMosaic[float2(imageSize) * fragmentUV];
}

void sampleColorAtPoint(float2 fragUV, float2 delta, uint viewIndex, float fragDepth, inout float kernelSum, inout float3 colorSum) {
    float2 uv = clamp(fragUV + delta / imageSize, float2(0.0, 0.0), float2(1.0, 1.0));

    // float distanceSq = dot(delta, delta);
    // float weight = exp(-distanceSq / (2.0f * sigma * sigma));

    float4 sampleColor = getColorMosaic(uv, viewIndex);
    if (sampleColor.w < 1.0) {
        // Discard samples which lie in wholes.
        return;
    }

    // 0.0 -> near plane
    // 1.0 -> far plane
    float sampleDepth = Linear01DepthViewBased(uv, viewIndex);
    if (sampleDepth < fragDepth) { 
        // If the sampled point is nearer than the original fragment, discard it.
        return;
    }

    float weight = 1.0;
    weight *= exp(-length(delta));
    weight *= exp(-(fragDepth - sampleDepth));

    kernelSum += weight;
    colorSum += weight * sampleColor.rgb;
}

float4 frag(int2 coord) {
    float2 cellCoordinates = getCellCoordinates(float2(coord) / imageSize, gridSize);
    uint viewIndex = getViewIndex(cellCoordinates, gridSize);
    float2 fragUV = getCellTexCoords(cellCoordinates);

    // first and last image in the grid are the left and right camera
    uint gridCount = gridSize.x * gridSize.y;
    if (viewIndex == 0 || viewIndex == gridCount - 1) {
        return _colorMosaic[coord];
    }

    float fragDepth = Linear01DepthViewBased(fragUV, viewIndex);
    float4 cellColor = getColorMosaic(fragUV, viewIndex); // sample the color of the left camera texture
    if( cellColor.w >= 1.0) {
        // if the cell color is valid, return the original color
        return cellColor;
    }

    float kernelSum = 0.0;
    float3 colorSum = float3(0.0, 0.0, 0.0);

    sampleColorAtPoint(fragUV, float2(0.0, 0.0), viewIndex, fragDepth, kernelSum, colorSum);
    
    sampleColorAtPoint(fragUV, float2(1.0, 0.0), viewIndex, fragDepth, kernelSum, colorSum);
    sampleColorAtPoint(fragUV, float2(-1.0, 0.0), viewIndex, fragDepth, kernelSum, colorSum);
    sampleColorAtPoint(fragUV, float2(0.0, 1.0), viewIndex, fragDepth, kernelSum, colorSum);
    sampleColorAtPoint(fragUV, float2(0.0, -1.0), viewIndex, fragDepth, kernelSum, colorSum);

    for (int i = 0; i < radius; i++) {
        sampleColorAtPoint(fragUV, float2(i, 0.0), viewIndex, fragDepth, kernelSum, colorSum);
        sampleColorAtPoint(fragUV, float2(-i, 0.0), viewIndex, fragDepth, kernelSum, colorSum);
        sampleColorAtPoint(fragUV, float2(0.0, i), viewIndex, fragDepth, kernelSum, colorSum);
        sampleColorAtPoint(fragUV, float2(0.0, -i), viewIndex, fragDepth, kernelSum, colorSum);
    }

    // float a = 1.0;
    // float b = 1.0;
    // float2 samplePoint = float2(0.0, 0.0);
    // float side = 1.0;

    // float2 stride = float2(1.0, 1.0);
    // for (uint i = 0; i < (uint) radius; i++) {

    //     // Sample at current Fibonacci point
    //     sampleColorAtPoint(fragUV, samplePoint * 0.5f, viewIndex, fragDepth, kernelSum, colorSum);

    //     // Generate next point on the Fibonacci spiral
    //     if (i > 1) {
    //         float next = a + b;
    //         a = b;
    //         b = next;
    //         side = b;
    //     }

    //     float2 square = float2(side, side);

    //     if ((i >> 1) & 1 != 0) {
    //         square.x *= -1.0;
    //     }
    //     if (((i + 1) >> 1) & 1 != 0) {
    //         square.y *= -1.0;
    //     }

    //     samplePoint += square;
    // }
    
    if (kernelSum == 0.0) {
        return float4(1.0, 0.5, 0.1, 1.0); // return orange if no samples were collected
    }

    return float4(colorSum / kernelSum, 1.0); // return the average color of the samples
}

[numthreads(1, 1, 1)]
void main(uint3 id : SV_DispatchThreadID)
{
    float2 coord = float2(id.x, id.y);
    float4 color = frag(coord);
    Result[coord] = color;
}
