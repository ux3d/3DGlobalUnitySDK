#include "Packages/com.unity.render-pipelines.high-definition/Runtime/RenderPipeline/RenderPass/CustomPass/CustomPassCommon.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/ShaderLibrary/ShaderVariables.hlsl"
#include "G3DHLSLCommonFunctions.hlsl"

#pragma kernel kernelFunction

Texture2D _depthMosaic;
SamplerState sampler_depthMosaic;
Texture2D _colorMosaic;
SamplerState sampler_colorMosaic;

// Create a RenderTexture with enableRandomWrite flag and set it
// with cs.SetTexture
RWTexture2D<float4> Result;


float4x4 inverseProjMatrix0;
float4x4 inverseProjMatrix1;
float4x4 inverseProjMatrix2;
float4x4 inverseProjMatrix3;
float4x4 inverseProjMatrix4;
float4x4 inverseProjMatrix5;
float4x4 inverseProjMatrix6;
float4x4 inverseProjMatrix7;
float4x4 inverseProjMatrix8;
float4x4 inverseProjMatrix9;
float4x4 inverseProjMatrix10;
float4x4 inverseProjMatrix11;
float4x4 inverseProjMatrix12;
float4x4 inverseProjMatrix13;
float4x4 inverseProjMatrix14;
float4x4 inverseProjMatrix15;

float4x4 viewMatrix0;
float4x4 viewMatrix1;
float4x4 viewMatrix2;
float4x4 viewMatrix3;
float4x4 viewMatrix4;
float4x4 viewMatrix5;
float4x4 viewMatrix6;
float4x4 viewMatrix7;
float4x4 viewMatrix8;
float4x4 viewMatrix9;
float4x4 viewMatrix10;
float4x4 viewMatrix11;
float4x4 viewMatrix12;
float4x4 viewMatrix13;
float4x4 viewMatrix14;
float4x4 viewMatrix15;



int grid_size_x;
int grid_size_y;
int radius;
float sigma;

uint imageWidth;
uint imageHeight;

Texture2D _depthMap0;
Texture2D _depthMap1;
Texture2D _depthMap2;
Texture2D _depthMap3;
Texture2D _depthMap4;
Texture2D _depthMap5;
Texture2D _depthMap6;
Texture2D _depthMap7;
Texture2D _depthMap8;
Texture2D _depthMap9;
Texture2D _depthMap10;
Texture2D _depthMap11;
Texture2D _depthMap12;
Texture2D _depthMap13;
Texture2D _depthMap14;
Texture2D _depthMap15;

SamplerState sampler_linear_repeat;

// Set the texture array as a shader input
float getCameraLogDepth(float2 uv, int cameraIndex) {
    switch(cameraIndex) {
        case 0:
            return _depthMap0.SampleLevel(sampler_linear_repeat, uv, 0).r;
        case 1:
            return _depthMap1.SampleLevel(sampler_linear_repeat, uv, 0).r;
        case 2:
            return _depthMap2.SampleLevel(sampler_linear_repeat, uv, 0).r;
        case 3:
            return _depthMap3.SampleLevel(sampler_linear_repeat, uv, 0).r;
        case 4:
            return _depthMap4.SampleLevel(sampler_linear_repeat, uv, 0).r;
        case 5:
            return _depthMap5.SampleLevel(sampler_linear_repeat, uv, 0).r;
        case 6:
            return _depthMap6.SampleLevel(sampler_linear_repeat, uv, 0).r;
        case 7:
            return _depthMap7.SampleLevel(sampler_linear_repeat, uv, 0).r;
        case 8:
            return _depthMap8.SampleLevel(sampler_linear_repeat, uv, 0).r;
        case 9:
            return _depthMap9.SampleLevel(sampler_linear_repeat, uv, 0).r;  
        case 10:
            return _depthMap10.SampleLevel(sampler_linear_repeat, uv, 0).r;  
        case 11:
            return _depthMap11.SampleLevel(sampler_linear_repeat, uv, 0).r;  
        case 12:
            return _depthMap12.SampleLevel(sampler_linear_repeat, uv, 0).r;  
        case 13:
            return _depthMap13.SampleLevel(sampler_linear_repeat, uv, 0).r;  
        case 14:
            return _depthMap14.SampleLevel(sampler_linear_repeat, uv, 0).r;  
        case 15:
            return _depthMap15.SampleLevel(sampler_linear_repeat, uv, 0).r;  
        default:
            return _depthMap0.SampleLevel(sampler_linear_repeat, uv, 0).r; // use left camera depth map as default
    }
}

float4x4 getInverseViewProjectionMatrix(int viewIndex) {
    switch (viewIndex) {
        case 0: return inverseProjMatrix0;
        case 1: return inverseProjMatrix1;
        case 2: return inverseProjMatrix2;
        case 3: return inverseProjMatrix3;
        case 4: return inverseProjMatrix4;
        case 5: return inverseProjMatrix5;
        case 6: return inverseProjMatrix6;
        case 7: return inverseProjMatrix7;
        case 8: return inverseProjMatrix8;
        case 9: return inverseProjMatrix9;
        case 10: return inverseProjMatrix10;
        case 11: return inverseProjMatrix11;
        case 12: return inverseProjMatrix12;
        case 13: return inverseProjMatrix13;
        case 14: return inverseProjMatrix14;
        case 15: return inverseProjMatrix15;
        default: return float4x4(1.0f, 1.0f, 1.0f, 1.0f,
                                    1.0f, 1.0f, 1.0f, 1.0f,
                                    1.0f, 1.0f, 1.0f, 1.0f,
                                    1.0f, 1.0f, 1.0f, 1.0f);
    }
}

float4x4 getViewMatrix(int viewIndex) {
    switch (viewIndex) {
        case 0: return viewMatrix0;
        case 1: return viewMatrix1;
        case 2: return viewMatrix2;
        case 3: return viewMatrix3;
        case 4: return viewMatrix4;
        case 5: return viewMatrix5;
        case 6: return viewMatrix6;
        case 7: return viewMatrix7;
        case 8: return viewMatrix8;
        case 9: return viewMatrix9;
        case 10: return viewMatrix10;
        case 11: return viewMatrix11;
        case 12: return viewMatrix12;
        case 13: return viewMatrix13;
        case 14: return viewMatrix14;
        case 15: return viewMatrix15;
        default: return float4x4(1.0f, 0.0f, 0.0f, 0.0f,
                                    0.0f, 1.0f, 0.0f, 0.0f,
                                    0.0f, 0.0f, 1.0f, 0.0f,
                                    0.0f, 0.0f, 0.0f, 1.0f);
    }
}

// here UV is treated as a full screen UV coordinate
float2 calculateProjectedFragmentPosition(float2 uv, int viewIndex, float4x4 viewProjectionMatrix) {
    float logDepth = getCameraLogDepth(uv, viewIndex);
    // Sample the depth from the Camera depth texture.
    float deviceDepth = logDepth;

    // Reconstruct the world space positions.
    float3 worldPos = ComputeWorldSpacePosition(uv, deviceDepth, getInverseViewProjectionMatrix(viewIndex));

    float3 NDC = ComputeNormalizedDeviceCoordinatesWithZ(worldPos, viewProjectionMatrix); // convert from clip space to NDC coordinates
    
    return float2(NDC.xy); // return the difference between the shifted and original x coordinate
}

float Linear01DepthViewBased(float2 uv, int viewIndex) {
    float logDepth = getCameraLogDepth(uv, viewIndex);
    // Sample the depth from the Camera depth texture.
    float deviceDepth = logDepth;
    float3 worldPos = ComputeWorldSpacePosition(uv, deviceDepth, getInverseViewProjectionMatrix(viewIndex));
    float eyeDepth = LinearEyeDepth(worldPos, getViewMatrix(viewIndex));
    return eyeDepth / _ProjectionParams.z; // convert to linear depth in range [0, 1]
}

float4 getColorMosaic(float2 uv, int viewIndex) {
    float2 fragmentUV = calculateUVForMosaic(viewIndex, uv, grid_size_y, grid_size_x);
    // return _colorMosaic.Sample(sampler_colorMosaic, fragmentUV);
    // return float4(1.0, 0.0, 0.0, 1.0);

    return _colorMosaic.Load(int3(imageWidth * fragmentUV.x, imageHeight * fragmentUV.y, 0));
}

void sampleColorAtPoint(float2 samplePoint, float2 cellTexCoords, uint viewIndex, float depthAtCenter, inout float kernelSum, inout float4 colorSum) {
    float dx = samplePoint.x / imageWidth;
    float dy = samplePoint.y / imageHeight;
    float x = clamp(cellTexCoords.x + dx, 0, 1.0f);
    float y = clamp(cellTexCoords.y + dy, 0, 1.0f);

    // float distance = sqrt(dpxX * dpxX + dpxY * dpxY);
    // float weight = exp(-(distance * distance) / (2.0f * sigma * sigma));
    float distanceSq = dot(samplePoint, samplePoint);
    // float weight = exp(-distanceSq / (2.0f * sigma * sigma));
    float2 sampleUV = float2(x, y);

    float depth_sample = Linear01DepthViewBased(sampleUV, viewIndex);
    float4 color_sample = getColorMosaic(sampleUV, viewIndex);

    if (color_sample.w < 1.0f) {
        // only collect colors from known values -> skip holes
        // weight = 0.0f;
        return;
    }

    float weight = 0.0f; // default weight is 0.0
    if (depth_sample < depthAtCenter) { // 0.0=front | 1.0=back
        // if center is further at the back then skip sample or reduce weight

        weight = 0.0f;
    } else {
        // reduce weight with distance to center:
        float diff = abs(depthAtCenter - depth_sample);
        // weight = weight * (diff * diff);
        weight = 1.0f;
        weight /= distanceSq + 0.01;
    }

    kernelSum += weight;
    colorSum += weight * color_sample;
}

float4 fragHDRP(float2 uv, int2 coord) {
    float2 cellCoordinates = getCellCoordinates(float2(coord) / float2(imageWidth, imageHeight), int2(grid_size_x, grid_size_y));
    uint viewIndex = getViewIndex(cellCoordinates, int2(grid_size_x, grid_size_y));
    float2 cellTexCoords = getCellTexCoords(cellCoordinates);

    // first and last image in the grid are the left and right camera
    uint gridCount = grid_size_x * grid_size_y;
    if (viewIndex == 0 || viewIndex == gridCount - 1) {
        return _colorMosaic.Load(int3(coord, 0));
    }

    float px_radius_left = 0;
    float px_radius_right = 0;

    float depthAtCenter = Linear01DepthViewBased(cellTexCoords, viewIndex);
    float4 cellColor = getColorMosaic(cellTexCoords, viewIndex); // sample the color of the left camera texture
    if( cellColor.w >= 1.0f) {
        // if the cell color is valid, return the original color
        return cellColor;
    }

    float kernelSum = 0.0f;
    float4 colorSum = float4(0.0f, 0.0f, 0.0f, 0.0f);

    // Sample at (1, 0)
    {
        float2 samplePoint = float2(1.0, 0.0);
        sampleColorAtPoint(samplePoint, cellTexCoords, viewIndex, depthAtCenter, kernelSum, colorSum);
    }

    // Sample at (-1, 0)
    {
        float2 samplePoint = float2(-1.0, 0.0);
        sampleColorAtPoint(samplePoint, cellTexCoords, viewIndex, depthAtCenter, kernelSum, colorSum);
    }
    
    // Sample at (0, 1)
    {
        float2 samplePoint = float2(0.0, 1.0);
        sampleColorAtPoint(samplePoint, cellTexCoords, viewIndex, depthAtCenter, kernelSum, colorSum);
    }
    
    // Sample at (0, -1)
    {
        float2 samplePoint = float2(0.0, -1.0);
        sampleColorAtPoint(samplePoint, cellTexCoords, viewIndex, depthAtCenter, kernelSum, colorSum);
    }

    float a = 1.0;
    float b = 1.0;
    float2 samplePoint = float2(0.0, 0.0);
    float side = 1.0;

    float2 stride = float2(1.0, 1.0);
    for (uint i = 0; i < (uint) radius; i++) {

        // Sample at current Fibonacci point
        sampleColorAtPoint(samplePoint * 0.5f, cellTexCoords, viewIndex, depthAtCenter, kernelSum, colorSum);

        // calculate new Fibonacci point
        if (i > 1) {
            float next = a + b;
            a = b;
            b = next;
            side = b;
        }

        float2 square = float2(side, side);

        if ((i >> 1) & 1 != 0) {
            square.x *= -1.0;
        }
        if (((i + 1) >> 1) & 1 != 0) {
            square.y *= -1.0;
        }

        samplePoint += square;
    }
    
    if (kernelSum <= 0.01f) {
        return float4(1.0f, 0.5f, 0.1f, 1.0f); // return orange if no samples were collected
    }

    return float4(colorSum.xyz / kernelSum, 1.0f); // return the average color of the samples
}

[numthreads(32,32,1)]
void kernelFunction (uint3 id : SV_DispatchThreadID)
{
    uint numThreadsX = 32;
    uint numThreadsY = 32;

    uint xCohortSize = floor((imageWidth + numThreadsX) / numThreadsX);
    uint yCohortSize = floor((imageHeight + numThreadsY) / numThreadsY);

    for(uint i = 0; i < xCohortSize; i++) {
        for(uint j = 0; j < yCohortSize; j++) {
            uint x = id.x * xCohortSize + i;
            uint y = id.y * yCohortSize + j;

            if (x >= imageWidth || y >= imageHeight) {
                continue; // skip if out of bounds
            }

            float2 uv = float2(x, y) / float2(imageWidth, imageHeight);
            float4 color = fragHDRP(uv, int2(x, y));

            Result[float2(x, y)] = color;
        }
    }
}