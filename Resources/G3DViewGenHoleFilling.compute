#include "Packages/com.unity.render-pipelines.high-definition/Runtime/RenderPipeline/RenderPass/CustomPass/CustomPassCommon.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/ShaderLibrary/ShaderVariables.hlsl"
#include "G3DHLSLCommonFunctions.hlsl"

#pragma kernel main

Texture2D _depthMosaic;
SamplerState sampler_depthMosaic;
Texture2D _colorMosaic;
SamplerState sampler_colorMosaic;

// Create a RenderTexture with enableRandomWrite flag and set it
// with cs.SetTexture
RWTexture2D<float4> Result;


float4x4 inverseProjMatrix0;
float4x4 inverseProjMatrix1;
float4x4 inverseProjMatrix2;
float4x4 inverseProjMatrix3;
float4x4 inverseProjMatrix4;
float4x4 inverseProjMatrix5;
float4x4 inverseProjMatrix6;
float4x4 inverseProjMatrix7;
float4x4 inverseProjMatrix8;
float4x4 inverseProjMatrix9;
float4x4 inverseProjMatrix10;
float4x4 inverseProjMatrix11;
float4x4 inverseProjMatrix12;
float4x4 inverseProjMatrix13;
float4x4 inverseProjMatrix14;
float4x4 inverseProjMatrix15;

float4x4 viewMatrix0;
float4x4 viewMatrix1;
float4x4 viewMatrix2;
float4x4 viewMatrix3;
float4x4 viewMatrix4;
float4x4 viewMatrix5;
float4x4 viewMatrix6;
float4x4 viewMatrix7;
float4x4 viewMatrix8;
float4x4 viewMatrix9;
float4x4 viewMatrix10;
float4x4 viewMatrix11;
float4x4 viewMatrix12;
float4x4 viewMatrix13;
float4x4 viewMatrix14;
float4x4 viewMatrix15;



int2 gridSize;
int radius;
float sigma;

int2 imageSize;

Texture2D _depthMap0;
Texture2D _depthMap1;
Texture2D _depthMap2;
Texture2D _depthMap3;
Texture2D _depthMap4;
Texture2D _depthMap5;
Texture2D _depthMap6;
Texture2D _depthMap7;
Texture2D _depthMap8;
Texture2D _depthMap9;
Texture2D _depthMap10;
Texture2D _depthMap11;
Texture2D _depthMap12;
Texture2D _depthMap13;
Texture2D _depthMap14;
Texture2D _depthMap15;

SamplerState sampler_linear_repeat;

// Set the texture array as a shader input
float getCameraLogDepth(float2 uv, int cameraIndex) {
    switch(cameraIndex) {
        case 0:
            return _depthMap0.SampleLevel(sampler_linear_repeat, uv, 0).r;
        case 1:
            return _depthMap1.SampleLevel(sampler_linear_repeat, uv, 0).r;
        case 2:
            return _depthMap2.SampleLevel(sampler_linear_repeat, uv, 0).r;
        case 3:
            return _depthMap3.SampleLevel(sampler_linear_repeat, uv, 0).r;
        case 4:
            return _depthMap4.SampleLevel(sampler_linear_repeat, uv, 0).r;
        case 5:
            return _depthMap5.SampleLevel(sampler_linear_repeat, uv, 0).r;
        case 6:
            return _depthMap6.SampleLevel(sampler_linear_repeat, uv, 0).r;
        case 7:
            return _depthMap7.SampleLevel(sampler_linear_repeat, uv, 0).r;
        case 8:
            return _depthMap8.SampleLevel(sampler_linear_repeat, uv, 0).r;
        case 9:
            return _depthMap9.SampleLevel(sampler_linear_repeat, uv, 0).r;  
        case 10:
            return _depthMap10.SampleLevel(sampler_linear_repeat, uv, 0).r;  
        case 11:
            return _depthMap11.SampleLevel(sampler_linear_repeat, uv, 0).r;  
        case 12:
            return _depthMap12.SampleLevel(sampler_linear_repeat, uv, 0).r;  
        case 13:
            return _depthMap13.SampleLevel(sampler_linear_repeat, uv, 0).r;  
        case 14:
            return _depthMap14.SampleLevel(sampler_linear_repeat, uv, 0).r;  
        case 15:
            return _depthMap15.SampleLevel(sampler_linear_repeat, uv, 0).r;  
        default:
            return _depthMap0.SampleLevel(sampler_linear_repeat, uv, 0).r; // use left camera depth map as default
    }
}

float4x4 getInverseViewProjectionMatrix(int viewIndex) {
    switch (viewIndex) {
        case 0: return inverseProjMatrix0;
        case 1: return inverseProjMatrix1;
        case 2: return inverseProjMatrix2;
        case 3: return inverseProjMatrix3;
        case 4: return inverseProjMatrix4;
        case 5: return inverseProjMatrix5;
        case 6: return inverseProjMatrix6;
        case 7: return inverseProjMatrix7;
        case 8: return inverseProjMatrix8;
        case 9: return inverseProjMatrix9;
        case 10: return inverseProjMatrix10;
        case 11: return inverseProjMatrix11;
        case 12: return inverseProjMatrix12;
        case 13: return inverseProjMatrix13;
        case 14: return inverseProjMatrix14;
        case 15: return inverseProjMatrix15;
        default: return float4x4(1.0f, 1.0f, 1.0f, 1.0f,
                                    1.0f, 1.0f, 1.0f, 1.0f,
                                    1.0f, 1.0f, 1.0f, 1.0f,
                                    1.0f, 1.0f, 1.0f, 1.0f);
    }
}

float4x4 getViewMatrix(int viewIndex) {
    switch (viewIndex) {
        case 0: return viewMatrix0;
        case 1: return viewMatrix1;
        case 2: return viewMatrix2;
        case 3: return viewMatrix3;
        case 4: return viewMatrix4;
        case 5: return viewMatrix5;
        case 6: return viewMatrix6;
        case 7: return viewMatrix7;
        case 8: return viewMatrix8;
        case 9: return viewMatrix9;
        case 10: return viewMatrix10;
        case 11: return viewMatrix11;
        case 12: return viewMatrix12;
        case 13: return viewMatrix13;
        case 14: return viewMatrix14;
        case 15: return viewMatrix15;
        default: return float4x4(1.0f, 0.0f, 0.0f, 0.0f,
                                    0.0f, 1.0f, 0.0f, 0.0f,
                                    0.0f, 0.0f, 1.0f, 0.0f,
                                    0.0f, 0.0f, 0.0f, 1.0f);
    }
}

// here UV is treated as a full screen UV coordinate
float2 calculateProjectedFragmentPosition(float2 uv, int viewIndex, float4x4 viewProjectionMatrix) {
    float logDepth = getCameraLogDepth(uv, viewIndex);
    // Sample the depth from the Camera depth texture.
    float deviceDepth = logDepth;

    // Reconstruct the world space positions.
    float3 worldPos = ComputeWorldSpacePosition(uv, deviceDepth, getInverseViewProjectionMatrix(viewIndex));

    float3 NDC = ComputeNormalizedDeviceCoordinatesWithZ(worldPos, viewProjectionMatrix); // convert from clip space to NDC coordinates
    
    return float2(NDC.xy); // return the difference between the shifted and original x coordinate
}

float Linear01DepthViewBased(float2 uv, int viewIndex) {
    float logDepth = getCameraLogDepth(uv, viewIndex);
    // Sample the depth from the Camera depth texture.
    float deviceDepth = logDepth;
    float3 worldPos = ComputeWorldSpacePosition(uv, deviceDepth, getInverseViewProjectionMatrix(viewIndex));
    float eyeDepth = LinearEyeDepth(worldPos, getViewMatrix(viewIndex));
    return eyeDepth / _ProjectionParams.z; // convert to linear depth in range [0, 1]
}

float4 getColorMosaic(float2 uv, int viewIndex) {
    float2 fragmentUV = calculateUVForMosaic(viewIndex, uv, gridSize.y, gridSize.x);
    return _colorMosaic[float2(imageSize) * fragmentUV];
}

void sampleColorAtPoint(float2 fragUV, float2 delta, uint viewIndex, float fragDepth, inout float kernelSum, inout float3 colorSum) {
    float2 uv = clamp(fragUV + delta / imageSize, 0, 1);

    float distanceSq = dot(delta, delta);
    // float weight = exp(-distanceSq / (2.0f * sigma * sigma));

    float4 sampleColor = getColorMosaic(uv, viewIndex);
    if (sampleColor.w < 1.0) {
        // Discard samples which lie in wholes.
        return;
    }

    // 0.0 -> near plane
    // 1.0 -> far plane
    float sampleDepth = Linear01DepthViewBased(uv, viewIndex);
    if (sampleDepth < fragDepth) { 
        // If the sampled point is nearer than the original fragment, discard it.
        return;
    }

    float diff = abs(fragDepth - sampleDepth);
    float weight = 1.0;
    // weight = weight * (diff * diff);
    weight /= distanceSq + 0.01;

    kernelSum += weight;
    colorSum += weight * sampleColor.rgb;
}

float4 frag(int2 coord) {
    float2 cellCoordinates = getCellCoordinates(float2(coord) / imageSize, gridSize);
    uint viewIndex = getViewIndex(cellCoordinates, gridSize);
    float2 fragUV = getCellTexCoords(cellCoordinates);

    // first and last image in the grid are the left and right camera
    uint gridCount = gridSize.x * gridSize.y;
    if (viewIndex == 0 || viewIndex == gridCount - 1) {
        return _colorMosaic[coord];
    }

    float fragDepth = Linear01DepthViewBased(fragUV, viewIndex);
    float4 cellColor = getColorMosaic(fragUV, viewIndex); // sample the color of the left camera texture
    if( cellColor.w >= 1.0f) {
        // if the cell color is valid, return the original color
        return cellColor;
    }

    float kernelSum = 0.0;
    float3 colorSum = float3(0.0, 0.0, 0.0);

    sampleColorAtPoint(fragUV, float2(1.0, 0.0), viewIndex, fragDepth, kernelSum, colorSum);
    sampleColorAtPoint(fragUV, float2(-1.0, 0.0), viewIndex, fragDepth, kernelSum, colorSum);
    sampleColorAtPoint(fragUV, float2(0.0, 1.0), viewIndex, fragDepth, kernelSum, colorSum);
    sampleColorAtPoint(fragUV, float2(0.0, -1.0), viewIndex, fragDepth, kernelSum, colorSum);

    float a = 1.0;
    float b = 1.0;
    float2 samplePoint = float2(0.0, 0.0);
    float side = 1.0;

    float2 stride = float2(1.0, 1.0);
    for (uint i = 0; i < (uint) radius; i++) {

        // Sample at current Fibonacci point
        sampleColorAtPoint(fragUV, samplePoint * 0.5f, viewIndex, fragDepth, kernelSum, colorSum);

        // Generate next point on the Fibonacci spiral
        if (i > 1) {
            float next = a + b;
            a = b;
            b = next;
            side = b;
        }

        float2 square = float2(side, side);

        if ((i >> 1) & 1 != 0) {
            square.x *= -1.0;
        }
        if (((i + 1) >> 1) & 1 != 0) {
            square.y *= -1.0;
        }

        samplePoint += square;
    }
    
    if (kernelSum == 0.0) {
        return float4(1.0, 0.5, 0.1, 1.0); // return orange if no samples were collected
    }

    return float4(colorSum / kernelSum, 1.0); // return the average color of the samples
}

[numthreads(1, 1, 1)]
void main(uint3 id : SV_DispatchThreadID)
{
    float2 coord = float2(id.x, id.y);
    float4 color = frag(coord);
    Result[coord] = color;
}
